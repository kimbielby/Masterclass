{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import  inference\n",
    "import torch\n",
    "from models.model import get_model as gm\n",
    "from Utils import get_simple_image_filepaths as rin"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get device",
   "id": "f9b38a11b4b4e6e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ],
   "id": "cd0b5799c5d5df46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load checkpoint",
   "id": "630427e7440acb9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "use_extra_channels = True",
   "id": "75f91749418e8884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoint_path = \"./models/checkpoints/spill_model_5ch.pth\" if use_extra_channels else \"./models/checkpoints/spill_model_3ch.pth\"\n",
    "checkpoint = torch.load(\"models/checkpoints/spill_model_1.pth\", map_location=device)\n",
    "model = gm(device=device, in_channels=5 if use_extra_channels else 3, out_channels=3).to(device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ],
   "id": "21ef962cbad2789b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Infer multiple images",
   "id": "8f47a64d4352e65d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "directory = \"/home/s5727767/Documents/Coursework/Semester2/Masterclass/Green_Spill_Dataset/GreenSceneSeq/Motions/Alex Walking Colour Adjusted\"\n",
    "image_filepaths_list = rin(directory=directory)\n",
    "save_as_name_base = \"./data/outputs/despilled/despilled_alex_walking_\"\n",
    "\n",
    "\n",
    "for i in range(len(image_filepaths_list)):\n",
    "    img_path = image_filepaths_list[i]\n",
    "    save_as_name = f\"{save_as_name_base}{i}.png\"\n",
    "    inference.infer(img_path=img_path, model=model,\n",
    "                    device=device, output_path=save_as_name,\n",
    "                    use_extra_channels=use_extra_channels)\n"
   ],
   "id": "3c5593fca1f5868d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Infer single image",
   "id": "c1c4cf8c289aabe1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image_filepath = \"\"\n",
    "save_as_name = \"\"\n",
    "inference.infer(img_path=image_filepath, model=model,\n",
    "                device=device, output_path=save_as_name,\n",
    "                use_extra_channels=use_extra_channels)\n",
    "\n"
   ],
   "id": "9ff33009aae86130"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
